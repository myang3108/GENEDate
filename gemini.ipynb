{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from rake_nltk import Rake\n",
    "\n",
    "df = pd.read_csv(\"FinalDF.csv\")\n",
    "\n",
    "# Target keywords\n",
    "target_keywords = [\"race\"]\n",
    "\n",
    "# Initialize Rake for keyword extraction\n",
    "r = Rake()\n",
    "\n",
    "df[\"Similarity Score\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Function to find synonyms of a word using WordNet\n",
    "def find_synonyms(word):\n",
    "        synonyms = set()\n",
    "        for synset in wn.synsets(word):\n",
    "            for lemma in synset.lemmas():\n",
    "                synonyms.add(lemma.name().lower())\n",
    "        return synonyms\n",
    "\n",
    "# Preprocess the keywords and text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Preprocessed target keywords\n",
    "preprocessed_target_keywords = [stemmer.stem(word.lower())[:5] for word in target_keywords if word.lower() not in stop_words]\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    text = df.at[i, 'Description']\n",
    "\n",
    "    # Extract keywords from the text using RAKE\n",
    "    r.extract_keywords_from_text(text)\n",
    "    rake_keywords = r.get_ranked_phrases()    \n",
    "\n",
    "    # Preprocessed RAKE keywords\n",
    "    preprocessed_rake_keywords = []\n",
    "    for keyword in rake_keywords:\n",
    "        preprocessed_rake_keywords.extend([stemmer.stem(word.lower())[:5] for word in word_tokenize(keyword) if word.lower() not in stop_words])\n",
    "\n",
    "    # Expand keyword list with synonyms\n",
    "    expanded_keywords = set(preprocessed_rake_keywords)\n",
    "    for keyword in preprocessed_rake_keywords:\n",
    "        synonyms = find_synonyms(keyword)\n",
    "        synonyms = [stemmer.stem(synonym)[:5] for synonym in synonyms]\n",
    "        expanded_keywords.update(synonyms)\n",
    "\n",
    "    #Preprocess the text\n",
    "    preprocessed_text = [stemmer.stem(word.lower())[:5] for word in word_tokenize(text) if word.lower() not in stop_words]\n",
    "\n",
    "    # Create vectors for the text and target keywords\n",
    "    text_vector = np.array([word in preprocessed_text for word in expanded_keywords], dtype=int)\n",
    "    target_vector = np.array([word in preprocessed_target_keywords for word in expanded_keywords], dtype=int)\n",
    "\n",
    "    # Reshape vectors for compatibility\n",
    "    text_vector = text_vector.reshape(1, -1)\n",
    "    target_vector = target_vector.reshape(1, -1)\n",
    "\n",
    "    # Calculate the cosine similarity between the text vector and the target keywords vector\n",
    "    similarity = cosine_similarity(text_vector, target_vector)[0][0]\n",
    "\n",
    "    # print(\"Cosine Similarity Score for the entire text:\", similarity)\n",
    "    df.at[i, 'Similarity Score'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = df.loc[~(df['Similarity Score'] == 0)]\n",
    "df =df.sort_values('Similarity Score', ascending=False)\n",
    "df = df.drop_duplicates('Name')\n",
    "df = df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Similarity Score', 'Unnamed: 0', 'Year', 'Term', 'Subject', 'Number', 'Start Time', 'End Time', 'Days of Week'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "json = df.to_json()\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
