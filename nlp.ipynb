{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "rake_class = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Interdisciplinary introduction to the basic concepts and approaches in Asian American Studies. \n",
    "Surveys the various dimensions of Asian American experiences including history, social organization, literature, arts, and politics.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writing computer code', 'computer program', 'implement algorithms', 'program', 'algorithms', 'translation', 'solve', 'represented', 'pseudocode', 'programs', 'programming', 'programming', 'problem', 'flowchart', 'created', 'create']\n"
     ]
    }
   ],
   "source": [
    "rake_class.extract_keywords_from_text(text)\n",
    "extracted_keyword = rake_class.get_ranked_phrases()\n",
    "print(extracted_keyword)\n",
    "extracted_keyword.append('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(x,y):\n",
    "  \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "  intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "  union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "  return intersection_cardinality/float(union_cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input1= 'Asian '\n",
    "user_input2= 'Asians'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = jaccard_similarity(user_input1, extracted_keyword)\n",
    "b = jaccard_similarity(user_input2, extracted_keyword)\n",
    "c = jaccard_similarity(extracted_keyword, extracted_keyword)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text: tokenize, lowercase, remove stopwords, and stem\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    tokens_and_synonyms = set()\n",
    "    for token in tokens:\n",
    "        synonyms = set()\n",
    "        for synset in wn.synsets(token):\n",
    "            for lemma in synset.lemmas():\n",
    "                synonyms.add(lemma.name().lower())  # Convert synonyms to lowercase\n",
    "        tokens_and_synonyms.add(stemmer.stem(token))  # Add original token\n",
    "        tokens_and_synonyms.update(stemmer.stem(synonym) for synonym in synonyms)  # Add synonyms\n",
    "    return tokens_and_synonyms\n",
    "\n",
    "# Function to compute Jaccard similarity with preprocessing\n",
    "def jaccard_similarity_preprocessed(text1, text2):\n",
    "    set1 = preprocess_text(text1)\n",
    "    set2 = preprocess_text(text2)\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013888888888888888\n",
      "0.013888888888888888\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = jaccard_similarity_preprocessed(user_input1, text)\n",
    "b = jaccard_similarity_preprocessed(user_input2, text)\n",
    "c = jaccard_similarity_preprocessed(text, text)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
